TEST.diffmean(DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"],DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far"],alternative = "great")
TEST.diffmean(DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"],DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far"],alternative = "less")
TEST.diffmean(DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"],DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far"],alternative = "less",digits = 6)
TEST.diffmean(y=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"],x=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far"],alternative = "less",digits = 6)
TEST.diffmean(y=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"],x=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far"],alternative = "great",digits = 6)
TEST.diffmean(x=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"],y=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far"],alternative = "great",digits = 6)
TEST.diffmean(x=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"&DS$Children==0],y=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far""&DS$Children==0],alternative = "great",digits = 6)
TEST.diffmean(x=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"&DS$Children==0],y=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far"&DS$Children==0],alternative = "great",digits = 6)
TEST.diffmean(x=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"&DS$Children==0],y=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far"&DS$Children==0],alternative = "less",digits = 6)
TEST.diffmean(x=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Close"&DS$Married=="Single"],y=DS$AmountSpent[DS$Gender=="Female"&DS$Location=="Far" &DS$Married=="Single"],alternative = "less",digits = 6)
distr.summary.x(DS$AmountSpent)
pnorm(0.11)
pnorm(0.11,,1288.47)
pnorm(0.11,,sd=sqrt(1288.47))
pnorm(186.327)
pnorm(0.11,0.1,sd = sqrt(0.11*0.89/500)
pnorm(0.11,0.1,sd = sqrt(0.11*0.89/500))
pnorm(0.11, 0.1, sd = sqrt(0.11*0.89/500))
1-pnorm(0.11, 0.1, sd = sqrt(0.11*0.89/500))
TEST.diffprop(vgsales$Genre[vgsales$Year==2016&vgsales$Genre=="Role-Playing"],vgsales$Genre[vgsales$Year==2006&vgsales$Genre=="Role-Playing"])
TEST.diffprop(vgsales$Genre[vgsales$Year==2016],vgsales$Genre[vgsales$Year==2006],success.x = "Role-Playing",,success.y = "Role-Playing")
1-TEST.diffprop(vgsales$Genre[vgsales$Year==2016],vgsales$Genre[vgsales$Year==2006],success.x = "Role-Playing",,success.y = "Role-Playing")
1-TEST.diffprop(y=vgsales$Genre[vgsales$Year==2016],x=vgsales$Genre[vgsales$Year==2006],success.x = "Role-Playing",,success.y = "Role-Playing")
distr.table.x(vgsales$Genre[vgsales$Year==2016])
distr.table.x(vgsales$Genre[vgsales$Year==2006])
pnorm(0.1695)
pnorm(0.1)
qnorm(0.1)
pnorm(3.22)
1-pnorm(3.22)
qt(p = 0.05,df = 8)
vgsales$bestsellerna<-vgsales$NA_Sales>1
TEST.diffprop(vgsales$bestsellerna[vgsales$Publisher=="Electronic Arts"],vgsales$bestsellerna[vgsales$Publisher=="Activision"])
TEST.diffmean(vgsales$NA_Sales[vgsales$Publisher=="Electronic Arts"],vgsales$EU_Sales[vgsales$Publisher=="Electronic Arts"])
pchisq(3.123,df = 3)
1-pchisq(3.123,df = 1)
qt(0.99,15)
qt(0.9,15)
qnorm(0.99)
pnorm(636.36,625,5)
1-pnorm(636.36,625,5)
table(DS$Children)
chisq.test(table(DS$Children),p = c(0.72,0.13,0.09,0.02)
chisq.test(table(DS$Children),p = c(0.72,0.13,0.09,0.02))
chisq.test(table(DS$Children),p = c(0.72,0.13,0.09,0.02))
chisq.test(table(DS$Children),p = c(0.76,0.13,0.09,0.02))
distr.table.x(DS$Children,freq = c("prop","count"))
1-qnorm(0.01)
pnorm(0.026,0.03,sqrt(0.026*(1-0.026)/1000))
TEST.diffmean(vgsales$JP_Sales[vgsales$Genre=="Fighting"],y = vgsales$Other_Sales[vgsales$Genre=="Fighting"]))
TEST.diffmean(vgsales$JP_Sales[vgsales$Genre=="Fighting"],vgsales$Other_Sales[vgsales$Genre=="Fighting"])
TEST.diffmean(vgsales$JP_Sales[vgsales$Genre=="Fighting"],vgsales$Other_Sales[vgsales$Genre=="Fighting"],type = "paired",alternative = "less")
TEST.diffmean(vgsales$JP_Sales[vgsales$Genre=="Fighting"],vgsales$Other_Sales[vgsales$Genre=="Fighting"],type = "paired",alternative = "great")
TEST.diffmean(vgsales$JP_Sales[vgsales$Genre=="Fighting"&vgsales$Year==2016],vgsales$Other_Sales[vgsales$Genre=="Fighting"&vgsales$Year==2016],type = "paired",alternative = "great")
TEST.diffmean(vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Strategy"],vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Simulation"])
TEST.diffmean(y=vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Strategy"],x=vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Simulation"])
TEST.diffmean(y=vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Strategy"],x=vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Simulation"],sigma.y = sqrrt(0.03),sigma.x = sqrt(0.05))
TEST.diffmean(y=vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Strategy"],x=vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Simulation"],sigma.y = sqrt(0.03),sigma.x = sqrt(0.05))
TEST.diffmean(y=vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Strategy"],x=vgsales$Global_Sales[vgsales$Year==2016 & vgsales$Genre=="Simulation"],sigma.y = sqrt(0.03),sigma.x = sqrt(0.05),alternative = "less")
dt(6.871,df = 22)
distr.table.x(vgsales$Genre[vgsales$Year==2016],freq = c("prop","count"))
distr.table.x(vgsales$Genre[vgsales$Year==2016],freq = c("prop","count"),p.digits = 5)
distr.table.x(vgsales$Genre[vgsales$Year==2016],freq = c("prop","count"),f.digits = 5)
qnorm(0.1)
qnorm(0.05)
qchisq(0.99,df = 4)
distr.table.x(vgsales$Other_Sales[vgsales$Year==2016&vgsales$Genre=="Action"])
distr.table.x(vgsales$Other_Sales[vgsales$Year==2016&vgsales$Genre=="Action"],freq = "count")
distr.summary.x(vgsales$Other_Sales[vgsales$Year==2016&vgsales$Genre=="Action"])
distr.summary.x(vgsales$Other_Sales[vgsales$Year==2016&vgsales$Genre=="Action"],f.digits = 5)
distr.summary.x(vgsales$Other_Sales[vgsales$Year==2016&vgsales$Genre=="Action"],f.digits = 5,digits = 6)
vgsales$osmillion<-vgsales$Other_Sales*(10^6)
distr.summary.x(vgsales$osmillion[vgsales$Year==2016&vgsales$Genre=="Action"],f.digits = 5,digits = 6)
TEST.mean(vgsales$osmillion[vgsales$Year==2016&vgsales$Genre=="Action"],mu0 = 16000,alternative = "less")
TEST.mean(vgsales$osmillion[vgsales$Year==2016&vgsales$Genre=="Action"],mu0 = 16000,alternative = "great")
TEST.mean(vgsales$osmillion[vgsales$Year==2016&vgsales$Genre=="Action"],mu0 = 16000,)
TEST.mean(vgsales$osmillion[vgsales$Year==2016&vgsales$Genre=="Action"],mu0 = 6500)
load("~/Downloads/Data_Exe8.RData")
View(TeleDebt)
View(TeleDebt)
lm(TeleDebt$Debt~TeleDebt$Television)
a<-lm(TeleDebt$Debt~TeleDebt$Television)
distr.summary.x(a)
table(a)
str(a)
summary(a)
distr.plot.xy(TeleDebt$Debt,TeleDebt$Television,plot.type = "scatter")
distr.plot.xy(TeleDebt$Debt,TeleDebt$Television,plot.type = "scatter",fitline = T)
predict(a,newdata = 33,level = 0.99 )
b=c(33,1)
predict(a,newdata = b,level = 0.99)
predict(a,newdata = frame(Television==33),interval = "pred",level = 0.99)
predict(a,newdata = frame(Television=33),interval = "pred",level = 0.99)
predict(a,newdata = data.frame(Television=33),interval = "pred",level = 0.99)
predict(a,newdata = data.frame(Television=33),interval = "pred",level = 0.99)
mod<-lm(TeleDebt$Debt~TeleDebt$Television)
summary(mod)
predict(mod,newdata = data.frame(Television=33),interval="prediction",level = 0.99)
predict(mod,data.frame(Television=33),interval = "prediction",level = 0.99)
mod
summary(mod)
#
mod<-lm(Debt~Television,data=TeleDebt)
summary(mod)
distr.summary.x(Television,stats="summary",data=TeleDebt)
predict(mod,data.frame(Television=33),interval = "prediction",level = 0.99)
predict(mod,data.frame(Television=33),interval = "prediction",level = 0.99)
b<-lm(Amount Spent~Salary,DS)
View(Commercials)
b<-lm(Amount Spent~Salary,data=DS)
b<- lm (formula = Amount Spent ~ Salary , data = DS)
b <- lm(formula = Amount Spent ~ Salary , data = DS)
c <- lm(Amount Spent~Salary,data=DS)
c <- lm(AmountSpent~Salary,data=DS)
summary(c)
distr.plot.xy(DS$Salary,DS$AmountSpent,fitline = T, plot.type = "scatter")
predict(mod,newdata = data.frame(20000),interval = "predict",level = 0.99)
predict(c,newdata = data.frame(20000),interval = "predict",level = 0.99)
predict(c,newdata = data.frame(Salary=20000),interval = "predict",level = 0.99)
d<-lm(Weeks~Age,data=Layoffs)
summary(d)
distr.plot.xy(Layoffs$Weeks,Layoffs$Age,plot.type = "scatter",fitline = T)
predict(d,interval = "predict",level = 0.9)
predict(d,data.frame(Age=36),interval = "predict",level = 0.9)
predict(d,data.frame(Age=36),interval = "predict",level = 0.99)
plot(sreg.model,which=1)
plot(d,which=1)
plot(d,which=2)
plot(d,which=4)
plot(d,which=5)
View(restaurants)
e<-lm(revenues~surface,data=restaurants)
sumamry(e)
summary(e)
distr.plot.xy(restaurants$revenues,restaurants$surface,plot.type = "scatt",fitline = T)
plot(d,which = 1)
plot(d,which = 2)
distr.plot.xy(restaurants$evening_only,rstandard(d),plot.type = "box")
#7.6
e<-lm(Employment~Age,data=Turnover)
summary(e)
qnorm(0.005)
qnorm(0.005)*2
qnorm(0.05)
confint(e,,0.95)
View(Turnover)
a<-lm(Employment~Age,data = Turnover)
summary(a)
distr.plot.xy(Turnover$Employment,Turnover$Age,plot.type = "scatt",fitline = T)
confint(a,level=0.05)
confint(a,level=0.95)
plot(lm,which=1)
plot(a,which=1)
plot(a,which=2)
plot(a,which=4)
plot(a,which=5)
predict(a,newdata = 27,interval = "predict",level = 0.9 )
predict(a,newdata = data.frame(Age=27),interval = "predict",level = 0.9 )
View(Commercials)
a<-lm(Test,Length,data=Commercials)
a<-lm(Test~Length,data=Commercials)
summary(a)
distr.plot.xy(Commercials$Test,Commercials$Length,plot.type = "scatter",fitline = T)
qt(0.98,df = 59)
qt(0.975,df = 59)
qt(0.975,df = 59)*0.05505
plot(a,which=1)
plot(a,which=2)
predict(a,newdata = data.frame(Lenght=36),interval = "predict",df = 0.99,level = "confi")
predict(a,newdata = data.frame(Length=36),interval = "predict",df = 0.99,level = "confi")
predict(a,newdata = data.frame(Length=36),interval = "predict",df = 0.99,)
predict(a,newdata = data.frame(Length=36),interval = "predict",df = 0.99,level = Tolerance)
predict(a,newdata = data.frame(Length=36),interval = "predict",df = 0.99,level = "Tolerance")
predict(a,newdata = data.frame(Length=36),interval = "predict",df = 0.99,level = 1)
predict(a,newdata = data.frame(Length=36),interval = "predict",df = 0.99,level = 0)
predict(a,newdata = data.frame(Length=36),interval = "predict",df = 0.99,level = 2)
distr.plot.xy(Commercials$Age,rstandard(a),plot.type = "box")
predict(a,newdata = data.frame(Length=36),interval = "predict",df = 0.99)
predict(a,newdata = data.frame(Length=36),interval = "conf",df = 0.99)
View(RepeatedAds)
a<- lm(Aad,Rep,Data=RepeatedAds)
a<- lm(Aad~Rep,Data=RepeatedAds)
a<- lm(Aad~Rep,Data=RepeatedAds)
a <- lm(Aad~Rep,data = RepeatedAds)
summary(a)
plot(a,which=1)
load("~/Downloads/Data_Exe9.RData")
View(Baseball)
a <- lm(Major~Minor+Age,data = Baseball)
summary(a)
predict(a,interval = "predict",newdata = data.frame(Age=25&Minor=22))
predict(a,interval = "predict",newdata= data.frame(Age=25&Minor=22))
predict(a,interval = "predict",newdata=data.frame(Age=25&Minor=22))
predict(a,newdata = data.frame(Age=25+Minor=22))
predict(a,newdata = data.frame(Age=25,Minor=22))
predict(a,newdata = data.frame(Age=25,Minor=22),interval = "predict")
2*confint(a)[3]
predict(a,newdata = data.frame(Age=25,Minor=22),interval = "predict",level = 0.95)
b<-lm(Major~Minor+Age+Years,data=Baseball)
summary(b)
1-pf(12.234,df=2,df=(30-2-1))
1-pf(12.234,df1=2,df2=(30-2-1))
pnorm(0.995)
pnorm(2500,5250,2500)
pnorm(2500,5250,1250)
pnorm(2500,5000,1250)
library(UBStats)
qnorm(0.025)
qnorm(0.05)
qnorm(0.01)
head(Sales)
plot(Sales$Price,Sales$Sales)
load("~/.RData")
m1
Sales$
# The Sales dataframe contains information on the weekly sales
# (Sales, in appropriate units) of a product, the price (Price)
# at which it was offered (at a certain shop, as a percentage)
# and the price at which the main competing product was offered (Price.Comp)
Sales$
head(Sales)
head(Sales)
gemini
detach("package:BizDecisionMath", unload = TRUE)
library(BizDecisionMath)
question1="Consider an ordinary perpetuity with semi-annual payments as follows: the amount of each of the first 10 instalments is €500, from the eleventh installment on the amount of each instalment is €200. The annual interest rate is r = 10%.(a) (2pts) Calculate the semi-annual interest rate equivalent to r."
ask_gemini_tutor(question = question1)
Sys.setenv(GEMINI_API_KEY = "AIzaSyBpLmo5ty4lXCDkrA0eN17m4wPDnqh9xiU")
ask_gemini_tutor(question = question1)
r1=ask_gemini_tutor(question = question1)
r1
print(r1)
detach("package:BizDecisionMath", unload = TRUE)
library(BizDecisionMath)
q2=ask_gemini_tutor(question = question1)
q2
a1=ask_gemini_tutor(question = question1)
q2="ordinary perpetuity semi annual payment, first 10 installment is 500 from elevne installment 200, interest rate = 0.1,calculate present value perpetuity"
a2=ask_gemini_tutor(question=q2)
a1
a2
a3=ask_gemini_tutor(question=q3)
q3="ordinary perpetuity semi annual payment, first 10 installment is 500 from elevne installment 200, interest rate = 0.1we replace the described perpetuity with ordinary annuity with semi annual payment and duration of 10 year, determine the amount of constant installment R so that the 2 investment has same present value"
a3=ask_gemini_tutor(question=q3)
a2a=ask_gemini_tutor(question=q2a)
q2a="capital structure cf = 0, -I ; 1, c1; ..;t,ct. state present value criterion for a decision maker and discount rate r"
a2a=ask_gemini_tutor(question=q2a)
q2b="capital structure cf = 0, -I ; 1, c1; ..;t,ct.report and justify main properties of NPV as a function of positive discounting r"
a2b=ask_gemini_tutor(question=q2b)
q3a=ask_gemini_tutor("put option european, non dividend stock price 30 k = 36 , T=12 months, instant risk rate = 0.05, u= u = 1.3132 and d = 0.8005.Construct the price tree of the underlying asset and calculate the risk-neutral probabilities according to a binomial model with two periods of 6 months each.")
q3b=ask_gemini_tutor("put option european, non dividend stock price 30 k = 36 , T=12 months, instant risk rate = 0.05, u= u = 1.3132 and d = 0.8005.Construct the put option price tree."
q3c=ask_gemini_tutor("put option european, non dividend stock price 30 k = 36 , T=12 months, instant risk rate = 0.05, u= u = 1.3132 and d = 0.8005.Using the put-call parity principle, calculate the price of the European call option corresponding to the described put option."
a3a=ask_gemini_tutor(question=q3a)
a3b=ask_gemini_tutor(question=q3b)
q3b="put option european, non dividend stock price 30 k = 36 , T=12 months, instant risk rate = 0.05, u= u = 1.3132 and d = 0.8005.Construct the put option price tree."
q3c="put option european, non dividend stock price 30 k = 36 , T=12 months, instant risk rate = 0.05, u= u = 1.3132 and d = 0.8005.Using the put-call parity principle, calculate the price of the European call option corresponding to the described put option."
a3b=ask_gemini_tutor(question=q3b)
a3c=ask_gemini_tutor(question=q2c)
a3c=ask_gemini_tutor(question=q3c)
a2a=ask_gemini_tutor(question=q2a)
a2a
a3a
a3b
a3c
q3c="put option european, non dividend stock price 30 k = 36 , T=12 months, instant risk rate = 0.05, u= u = 1.3132 and d = 0.8005.2 period. Using the put-call parity principle, calculate the price of the European call option corresponding to the described put option."
a3c=ask_gemini_tutor(question=q3c)
a3c
detach("package:BizDecisionMath", unload = TRUE)
library(BizDecisionMath)
q3c="put option european, non dividend stock price 30 k = 36 , T=12 months, instant risk rate = 0.05, u= u = 1.3132 and d = 0.8005.2 period. Using the put-call parity principle, calculate the price of the European call option corresponding to the described put option."
a3c=ask_gemini_tutor(question=q3c)
a3c
load("~/Downloads/CA_Houses.RData")
load("~/Downloads/Recommend.RData")
load("~/Downloads/Companies.RData")
summary(CA)
summary(Median_House_Value~Median_Income,data=CA)
moda=lm(Median_House_Value~Median_Income,data=CA))
moda=lm(Median_House_Value~Median_Income,data=CA)
summary(moda)
summary(ca)
summary(CA)
#a1 we can use the R^2 the R^2 is calculated as the ratio between explained variability by the model and unexplained variability,
#in our case we have an r^2 of 0.4787, if we had a model with more than 2 variables we could also used adjusted R^2 that have and adjustment for number of parm
#a2 in our model is 0.4787 it's not a super good model
#a3
modb=lm(Median_House_Value~Median_Income+Median_Age+Population)
#a1 we can use the R^2 the R^2 is calculated as the ratio between explained variability by the model and unexplained variability,
#in our case we have an r^2 of 0.4787, if we had a model with more than 2 variables we could also used adjusted R^2 that have and adjustment for number of parm
#a2 in our model is 0.4787 it's not a super good model
#a3
modb=lm(Median_House_Value~Median_Income+Median_Age+Population,data=CA)
summary(modb)
summary(CA)
#b2 yes we can see that the population we have a negative parameter for population law and population middle
#b3 b3) What is the predicted median value for a high-density housing neighbourhood where the median income is 5 tens of thousands of dollars and the median age of houses is 10 years?
predict(modb,data.frame(Median_Income=50000,Median_Age=10))
#b2 yes we can see that the population we have a negative parameter for population law and population middle
#b3 b3) What is the predicted median value for a high-density housing neighbourhood where the median income is 5 tens of thousands of dollars and the median age of houses is 10 years?
predict(modb,data.frame(Median_Income=50000,Median_Age=10,Population="High"))
## fit the model
modB <- lm(Median_House_Value ~ Median_Income + Median_Age + Population,
data = housing)   # <-- your data frame name
## fit the model
modB <- lm(Median_House_Value ~ Median_Income + Median_Age + Population,
data = CA)   # <-- your data frame name
## estimated effect of a +10 year change in Median_Age
effect_10yr <- 10 * coef(modB)["Median_Age"]
## 99% CI for the +10 year effect
ci_10yr <- 10 * confint(modB, "Median_Age", level = 0.99)
effect_10yr
ci_10yr
## Exercise 2
summary(CA)
logita=glm(House_Value_dummy~Median_Age+Tot_Rooms+Population,family = "binomial")
logita=glm(House_Value_dummy~Median_Age+Tot_Rooms+Population,family = "binomial",data=CA)
logitareduced=glm(House_Value_dummy~Median_Age+Tot_Rooms,family = "binomial",data=CA)
anova(logita,logitareduced,test="Chisq")
summary(logita)
exp(0.0244312)
# Exercise 3
summary(Reccomend)
# Exercise 3
summary(Recomend)
# Exercise 3
summary(Recommend)
mod3=multinom(Poll~Profitability+ESG,data=Recommend)
library(car)
mod3=multinom(Poll~Profitability+ESG,data=Recommend)
library(nnet)
mod3=multinom(Poll~Profitability+ESG,data=Recommend)
summary(mod3)
load("~/Downloads/GOOGLE.RData")
load("~/Downloads/file_debt.RData")
load("~/Downloads/advertising.RData")
load("~/Downloads/file_credit.RData")
load("~/Downloads/plants.RData")
#exercise 1
#a)
summary(credit)
mod1=lm(Balance~Purchases+Renter,data=credit)
summary(mod1)
#a1 the coefficient of the variable Renter Yes is -100.6343  that means that on avg ceteris parisbus the Balance of the Retner Yes is -100.6343 lower than Renter No
# keeping all the other variables constant, also we can see that his p value is significant for every signifcance level
#å2 purchase variable is significant at every level
predict(mod1,data.frame(Purchases=200,Renter="YES"))-predict(mod1,data.frame(Purchases=400,Renter="YES"))
predict(mod1,data.frame(Purchases=200,Renter="NO"))-predict(mod1,data.frame(Purchases=400,Renter="NO"))
predict(mod1,data.frame(Purchases=200,Renter="NO"))
#exercise 1
#a)
summary(credit)
#b
mod2=lm(Balance~Purchases*Age,data=credit)
summary(mod2)
mod2red=lm(Balance~Purchases,data=credit)
anova(mod2,mod2red,test="Chisq")
#b
mod2=lm(Balance~Purchases+Age,data=credit)
#exercise 1
#a)
summary(credit)
predict(mod2,data.frame(Purchases=5,Age="YOUNG"))
confint(mod2,data.frame(Purchases=5,Age="YOUNG"),level = 0.99)
aic(mod1,mod2)
aif(mod1,mod2)
#exercise 2
summary(debt)
moda=glm(REVIEW~DUR+RES_DEBT+WORK,data=debt,family=binomial(link="logit"))
p=predict(moda,data.frame(WORK=SE,RES_DEBT=40,DUR=60),type="response")
p=predict(moda,data.frame(WORK="SE",RES_DEBT=40,DUR=60),type="response")
p
summary(moda)
modared=glm(REVIEW~RES_DEBT+WORK,data=debt,family=binomial(link="logit"))
anova(moda,modared,test="Chisq")
#a1 using a chisq test the duration is significative
modared2=glm(REVIEW~DUR+RES_DEBT,data=debt,family=binomial(link="logit"))
anova(moda,modared2,test="Chisq")
#a2 a3 all using anova chisq yes they are significative
summary(modared2)
summary(modared)
summary(plants)
summary(P)
summary(PL)
model=multinom(COUNTRY~WORKERS+INNOVATION)
model=multinom(COUNTRY~WORKERS+INNOVATION,data=PL)
summary(model)
exp(-25.90390)
zscore=model$coefficients/model$standarderrors
pvalues=2*pnorm(-abs(zscore))
pvalues
zscore=model$coefficients//model$standarderrors
info=summary(model)
zscore=info$coefficients//info$standarderrors
pvalues=2*pnorm(-abs(zscore))
pvalues
zscore=info$coefficients/info$standarderrors
pvalues=2*pnorm(-abs(zscore))
pvalues
model <- multinom(COUNTRY ~ WORKERS + INNOVATION, data = PL, Hess = TRUE)
s <- summary(model)
z <- s$coefficients / s$standard.errors
pvalues <- 2 * pnorm(-abs(z))
pvalues
2.053409e-04 2.053409e-04
install.packages(plm)
install.packages("plm")
library(plm)
# 4
summary(P)
fe=plm(Sales~ADV1+ADV2+OFFER,data=P,model="fixed")
fe=plm(Sales~ADV1+ADV2+OFFER,data=P,model="within")
# 4
summary(P)
fe=plm(SALES~ADV1+ADV2+OFFER,data=P,model="within")
re=plm(SALES~ADV1+ADV2+OFFER,data=P,model="random")
phtest(fe,re)
#5
plot(G)
library(forecast)
fit=auto.arima(G,d = 2,seasonal = FALSE,ic = "aic",stepwise = FALSE,approximation=FALSE)
fit
summary(fit)
#5
plot(G)
modelG=auto.arima(G,d = 2)
summary(model)
summary(modelG)
modelG=auto.arima(G,d = 2,ic = "aic")
summary(modelG)
library(forecast)
#a Zt=-0.8556Zt-1 -0.6677 Zt-2  -0.5111 Zt-3 -0.3131 Zt-4 -0.1507Zt-5 + epsilon
res=residuals(modelG)
checkresiduals(res)
# looking at the graph we can see that the residuals have increasing volatiltiy going forward with time maybe we could try something with a log?
modelG2=auto.arima(log(G),d = 2,ic = "aic")
summary(modelG2)
res2=residuals(modelG2)
checkresiduals(res)
predict(modelG)
forecast(modelG)
calc_equivalent_rate(rate = 0.0975,m = 12)
cf=(-1000,3500,4500,2500)
cf=c(-1000,3500,4500,2500)
times=c(0,1,2,3)
calculate_npv(cash_flows = cf,times = times,i=0.007783037)
calculate_irr(cash_flows = cf, times = times)
calculate_irr(cash_flows = cf,times=times)
calculate_npv(cash_flows = cf,times = times,i = 0.007783037)
# Correct way:
i_monthly <- calc_equivalent_rate(0.0975, m = 12)
calculate_npv(c(-10000, 3500, 4500, 2500), i = i_monthly, verbose = TRUE)
# Correct way:
i_monthly <- calc_equivalent_rate(0.0975, m = 12)
calculate_npv(c(-10000, 3500, 4500, 2500), i = i_monthly)
i_monthly
detach("package:BizDecisionMath", unload = TRUE)
library(BizDecisionMath)
# Correct way:
i_monthly <- calc_equivalent_rate(0.0975, m = 12)
calculate_npv(c(-10000, 3500, 4500, 2500), i = i_monthly, verbose = TRUE)
B=c(-12000,3800,4200,4600)
calculate_npv(cash_flows = B,i=i_monthly)
calculate_npv(cash_flows = B,i=i_monthly,verbose = TRUE)
i_m=calc_equivalent_rate(rate=0.04,m=12,type = "annual_to_periodic")
binomial_option_price(S=25,K=24,T=26,i=i_m,u=1.583,d=0.689,verbose=TRUE)
binomial_option_price(S=25,K=24,T=26,r=i_m,u=1.583,d=0.689,n = 2)
devtools::load_all("~/Downloads/Data/BizDecisionMath")
binomial_option_price(S=25, K=24, r=0.04, T=26/12, n=2,
u=1.583, d=0.689, verbose=TRUE)
binomial_option_price(S=24,K=23,T=26/12,r = 0.04,u=1.551,d = 0.675,n = 2,verbose = TRUE)
binomial_option_price(S=24,K=23,T=26/12,r = 0.04,u=1.551,d = 0.675,n = 2,verbose = TRUE,type = "call")
> devtools::load_all("~/Downloads/Data/BizDecisionMath")
devtools::load_all("~/Downloads/Data/BizDecisionMath")
c0 <- binomial_option_price(
S = 35, K = 38, r = 0.03, T = 1, n = 2,
sigma = 0.10,  # CRR auto-calculates u, d, π
type = "call",
verbose = TRUE
)
devtools::install("/Users/francescodelsesto/Downloads/Data/BizDecisionMath", force = TRUE)
library(BizDecisionMath)
calc_equivalent_rate(rate=0.0975,m=12,type="periodic_to_annual")
remove.packages("BizDecisionMath")
devtools::install("/Users/francescodelsesto/Downloads/Data/BizDecisionMath", force = TRUE)
devtools::install("/Users/francescodelsesto/Downloads/Data/BizDecisionMath", force = TRUE)
devtools::install("/Users/francescodelsesto/Downloads/Data/BizDecisionMath", force = TRUE)
library(BizDecisionMath)
calc_equivalent_rate(rate=0.0975, m=12, type="periodic_to_annual")
calc_equivalent_rate(rate=0.0975, m=12, type="annual_to_periodic")
i=calc_equivalent_rate(rate=0.0975, m=12, type="annual_to_periodic")
calculate_npv(cash_flows = c(-10000,3500,4500,2500),i = i)
calculate_npv(cash_flows = c(-10000,3500,4500,2500),i = i,verbose = TRUE)
calculate_irr(cash_flows = c(-10000,3500,4500,2500),verbose = TRUE)
int=0.1
calc_equivalent_rate(rate=int,m = 2,type = "annual_to_periodic",verbose = TRUE)
devtools::install("/Users/francescodelsesto/Downloads/Data/BizDecisionMath", force = TRUE)
library(BizDecisionMath)
proof()
# 1. Set working directory to the package folder
setwd("/Users/francescodelsesto/Downloads/Data/BizDecisionMath")
# 2. Load the package in development mode
devtools::load_all()
devtools::load_all()
setwd("/Users/francescodelsesto/Downloads/Data/BizDecisionMath")
devtools::load_all()
# 1. Remove the corrupt installed package
remove.packages("BizDecisionMath")
# 2. Restart R (close and reopen RStudio/R)
# 3. After restart, set working directory and load from source
setwd("/Users/francescodelsesto/Downloads/Data/BizDecisionMath")
devtools::load_all()
q()
